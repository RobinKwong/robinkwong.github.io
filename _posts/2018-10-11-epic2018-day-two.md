---
layout: post
title: Epic 2018 day 2 conference notes
date: 2018-10-11 07:00
tags: [conference, ethnography]
permalink: /epic2018-day-two/
---

![](/images/epic2018/epiclogo.JPG)

- [Notes for day one](/epic2018-day-one/)

## Design & Data

_What does a data expert see when they look at a design problem? This panel will immerse us in the practices of two data experts, both of whom have collaborated with ethnographers, as they navigate through design challenges in different ways. Chair Jeanette Blomberg will draw the panelists and audience into conversation about synergies and challenges for interdisciplinary design collaborations._

![](/images/epic2018/panellists.PNG)

### Thomas Y Lee

Introducing innovation and product design as a process

![](/images/epic2018/linear.JPG)

Whether it's design thinking, product design or hypotehsis dirven devleopment, at a high level the process is fundamentally the same.

Rather than thinking of this as a linear or a stage-gate process, in practice it is often circular and contiuous

![](/images/epic2018/circular.JPG)

So, the question becomes - what is the role of data in this cycle?

Data has long had a role but traditionally this is afterwards - A/B testing, pre/post, etc. In all of these different frameworks, data fundamentally answers questions of how many or how much.

Textual/sentiment analysis for example use word baskets, which are ultimately just counting words.

In order to develop an intimate understanding of a problem, we really need to ask uestions about **'why'**

So, the question is:

"How can we apply processes related to data to begin to answer questions about why and how?"

Example / story:

Ace hardware store in SF. goes in and buys gloves, sweep, spray hose and clorox. Soon as I put items on counter, check-out person said: 'oh you're cleaning your compost bin'

_Can we identify customer intent based on items purchased?_

Customers aren't buying a 1/4 inch drill bit, they're intereste din a 1/4 inch hole. But push it further  - they want to hang a picutre/secure bookcase, etc.

Does domain knowledge (recipes or known projects) improve our abaility to identify projects?

going further: 
Does contextual knowledge (customer demographics) improve our ability to identify projects?


Second example/story:
emergency services wait times. 2 hours. 

In emergency services, wait time is an inverse function: the sicker you are the shorter you wait. 

We all know we need to wait, but what can we do about it? Because at the limit, people can die.

A traditional researcher would look at this and says, oh this is a non-pre-emptive priority queue. I'm going to map this thing out, I'm going to identify the bottlenecks in the process, and design a service impreovement to remove the bottleneck.

Instead of doing this, we said: traditional process design doesn't apply to healthcare, because no patient is a widget. Every patient is unique. So, build sequence algorithm to track each patient, and ultimately try to find a discrimation value and pushes it upstream. Point of care testing - tests that can be performed at the bedside. If you can convert tests to the bedside, recognising tradeoffs in cost vs efficiency, which would you do it for?

Big ideas:

Explore 'why' and 'how' with machine-generated data in additional 'how many' and 'how much'

Approach the analysis of machine-generated data as a complementary, not competing approach
- start with hypothese (semi-supervied methods)
- generate hypotheses (eg. narrow the scope of analysis)

Analyse: "What people do and how systems perform" and not just "What people say"

How can I use data to generate hyphotheses to then turn around and use ethnography to really look into the right areas?

### Marc Böhlen

![](/images/epic2018/marctitle.JPG)

Can machine learning algorithms detect beauty?

If we try to answer this question in the affirmative, we need an approach and some data. But data is hard to get and hard to make. So, borrow some data: CelebA data set from University of Hong Kong. 200k  face images of celebrities; 40 binary features

![](/images/epic2018/beauty.JPG)

What about approach? The current paradigm is deep learning. i.e. convolutional neural network for image classification.

![](/images/epic2018/CNN.JPG)

3 steps:

1. Data collection - need to be large amounts and high quality. Labels have to be correct and dimensions flattened to fit into framework

2. Training. 

3. Test it. introduce a new image and see what it classifies it. 

So question is: What's difference between testing data and training data? How can you get something that's precise and can be generalised.

Process raises many questions: From network perspective, when do you use a complex framework and when do you use a simple one? From a data perspective, what do you do with noise? i.e. false negatives/positives. Machine learning algorithms are supposed to be immune to that because of generalisation, but we want to 

University of Hong Kong hired 50 workers from mainland China to compile that data. 100 binary decisions per hour per worker. No wonder you're going to have mistakes because it's a rushed job.

There's a deeper problem than just the outsourcing of the labour. When you make these data sets, you are making a world. You are deciding what to include and what not to include. 

There's always slippage. These models get made and they get used for somethign slightly different, and it's hard to track.

Big data training sets problems: 

- Outsourcing of labour in data collection and therefore low quality of it. 
- Slippage in usage of those data sets.
- Lack of articulation of the assumptions that went into the selection criteria in the first place.

These are the video databases in 2018:

![](/images/epic2018/videodata.JPG)

An alterative approach, as an experiment: Action camera footage as the foundation for these databases. 

Because these footage comes closest to being ethnographic in nature. 

Also this data source is easy to access and make. And now the problems just begin:

- can extract metadata from the feed to say something very specific about activities and 

Shows NYT's artice classification curation workflow [very similar to ours at the FT] - involves humans-in-a-loop with machines.

![](/images/epic2018/nyt.JPG)

Q (from Thomas to Marc): If you use a commercial off the shelf tool, it has assumptions and limitation built into it. What advice for people starting out?

A: Hard problem, but intermediate approach is to compare across products. It's getting The convenience factors is really seductive. If it kinda works but you don't know why it doesn't fully work, don't do it.

Q (from Marc to Thomas): intrigued by the 'why' question. How do you separate out the components of why

A: Total quality management has its roots in Edward Demming. In application, as a process, people use the back-of-the envelope heuristics of 'The 5 Whys' - this gets you closer to the root causes. What is the user is really interested in. Yes there are other dimensions of 'why' but those dimenions are all secondary to the ultimate purpose.

Q (to Tom): Why not just ask the clerk? (in the Ace Hardware example)

A: Machine learning is all about learning from experience, so yes, can ask cleark. But which clerk do I ask? How many should I ask? Now I need to aggregate and reduce. 

Q: Class one / Class zero error tradeoff, especially when it comes to why in medical contexts.

A: There isn't a broad heuristic that works. I started down this field in medical infomatics. I'm skeptical about applying too many automation in medical information. Particularly because context is really important. Even just San Fran vs Philly - in SF you're worried about meth; in Philly you're worried about cocaine. Trying to generalise is a fool's errand in these circumstance because context is so important. 

Q: How to organise teams of humans to create high quality data sets? What are good examples? 

A: The 2018 crop of video datasets - there's good work in there. The challenge is - if you want the voice of the world in there, it can't be just the researchers saying we pick this or that. How do you combine getting authentic, real input with material that's useful for machine learning which is finicky and fragile and difficult to fit into.

## Shifting Power & Agency

Themes: Engaging evidence. How to use ethnography to effect change in a system.

![](/images/epic2018/powerandagency.JPG)

### Revitalising Openness at Mozilla: A Mixed Method Research Approach
Rina Jensen (@rinajensen) · Mozilla

Big takeaway: importance of mixed-method research. 

Open source is the main competitive advantage for Mozilla. But Mozilla is facing a dilemma. We're losing market share in a market we cannot compete directly. 

History from 2004 (release of Firefox) to today. As Mozilla grew, it became more open source in name than for real. 

"We now have a significantly large enough population of folks at Mozilla who don't have that history and don't know the history of Mozilla being built by the community."

Teams were spread out, making it hard to collaborate and learn. 

Our dilemma was not just organisational or cultural but existential. 

Wanted to revitalise Open, but institutionalised knowledge had been lost. 

So, engaged diverse group of researchers. Set forth 3 questions:

- What is the current state of open collaboration at Mozilla?

- What has changed and why?

- What are the other exmpales out there that Mozilla could draw from?

For the first time ever, did a deep-dive data analysis of contributors. 

Learnt that contribution was actually growing. But contribution has centralised around 6 projects, and Firefox as not one of those.

The feeling of being disconnected also came down to how the collaboration was happening. We had adopted closed systems - Slack, etc, that required people to sign in. 

"What people get frustrated about, what is the thing, is that the thing all of a sudden comes out and look different."

Diversity has a real impact - other open source projects worked on diversity, whereas Mozilla had never deliberately done so. 

Outcomes since 2017 December: Specific projects on diversity, launching 30+ projects to revitalise open source. 

### Holistic Understanding of Digital Financial Services Users: An Integrative Approach between Applied Anthropological Research and Big Data Analytics

Gisela Davico & Soren Heitmann · International Finance Corporation

Financial inclusion. Work in Sub-Saharan Africa to scale financial services. 57% of adults in Sub-Saharan Africa are still financially excluded. 

Getting people to sign up is a challenge, and getting them to use them after signing up is also a challenge. 

Research journey:

![](/images/epic2018/financial.JPG)

Found 6 factors that affect trust:

1. Historical roots of money transaction

2. Mobility of people and money (i.e. people already have experience with sending money)

3. Economic heirarchies (i.e. banks are not for me or people like me)

4. Risk perceptions (i.e. would my money be safe?)

5. Technological appropriations (i.e. takes away excuses, makes people interact in new ways)

6. Networks of belonging (i.e. I don't need the bank - I have informal social networks that give me what I need already)

How these six factors can be used:

![](/images/epic2018/sixfactors.JPG)

Also - they made a game to help convey the results!

Challenges: mainly around project management. 





